Transformers - Sequence-to-Sequence (Summarization)

`google/flan-t5-small` - smaller version of T5 large language model (encoder-decoder) is from Hugging Face:
https://huggingface.co/google/flan-t5-small.

Goals:
- Explore Hugging Face's transformers package to implement language tasks such as summarization.
- Perform text preprocessing and tokenization prior to using transformers.
- Choose the appropriate tokenizer and model configurations.
- Perform summarization tasks with encoder-decoder models.
